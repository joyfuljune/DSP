<h1 align="center"> 音频变速 </h1>

## 概述

音频信号的时间压缩或扩展，也称为“时间拉伸”，是音高转换的倒数过程。它在改变速度（节奏）的同时保持信号音高不变。它的实现并没有想象中那么简单，让我们看一个简单但失败的案例。

### 第一阶段思考

音频变速的一种直接的想法是对所有的语音信号进行插值处理，例如将一段时长为两分钟的语音信号拉伸为4分钟，可以设原始音频为N长，拉伸音频为2N，以最邻近插值法来说，假设音频信号为{1，2，3}，则拉伸后的数据为{1，1，2，2，3，3}。

下图是对一段音频的时域波形和以最邻近法作差值的结果。

![image](https://user-images.githubusercontent.com/88413945/185904888-4f3b1173-6fb1-400f-88bf-8c03d0b0c5b8.png)
![image](https://user-images.githubusercontent.com/88413945/185904905-f173a47f-7a85-457d-b1e4-95bb6480fe4a.png)

*图1. （左）原始语音信号，（右）拉伸2倍后语音信号*

从图像上看，信号被拉长了2倍，原始音频约5秒，拉伸后接近10秒，且波形相似。但是聆听拉伸后的音频stretched.wav对比原始音频orig.wav可以发现在音高，或者说频率上变低了，而这是我们不希望发生的。反过来，如果我们希望对原始音频进行加速，例如由2分钟变成1分钟，一种直接的思路是抽取信号中的一半，如保留所有的偶数信号值。聆听加速后的音频信号<code>compressed.wav</code<会发现音高升高，同样是一种错误的结果，如图3所示。

这种错误产生的原因很简单，图1和图2欺骗我们的地方在于他们的时间轴是不等的，如果将两者放在同一时间尺度下会得到图4的情况（请注意这里用正弦波表示**频率**，不是时间信号），由于时间和频率成反比的关系，我们无法通过直接改变音频时长而得到理想结果。

![image](https://user-images.githubusercontent.com/88413945/185905109-5440ef66-3711-4197-ab62-4355b733bc64.png)

*图2. 原始语音信号的频谱（左上）、拉伸信号的频谱（左中）、压缩信号的频谱（左下）*

![image](https://user-images.githubusercontent.com/88413945/185905117-50181a11-c6fd-44c4-bdf5-0b7b70cb52f7.png)

*图3. 语音拉伸（L到2L)对频谱的影响（正弦波频率下降）*

### 第二阶段思考

所以正确的做法要求在改变时长同时维持频率不变。我们简单看一下思路，假设对某L长度的信号作2倍拉伸，首先得到的是时域延长2倍，频域压缩2倍的音频信号。对频谱进行2倍抽取，重新组成新的频率值。

![image](https://user-images.githubusercontent.com/88413945/185905448-08338044-449d-42fa-bfcc-594c8a469664.png)

*图4. 频域插值方法*


### 第三阶段思考

这样的做法还存在一个问题就是我们通常对时域信号先进行分帧，在处理完成后再合并重建变速信号。

![image](https://user-images.githubusercontent.com/88413945/185905518-a30e3ef9-af57-4ab5-8204-c062f96fae1b.png)

*图5. 相位跳变*

a图中我们对原始信号分成L长度两帧，变速处理后频率保持不变，但时间长度调整为αL，观察b图中存在的问题是两帧衔接处产生了不连续性。这个小小的频率会在合成音频中产生杂音，为了消除它，我们调整b图中第二帧信号的**相位**，使其能够和第一帧相位对齐，如图c所示。这个概念来自于1966 Flanagan 和 Golden提出的相位声码器（phase vocoder）的概念。

## PV核心思想

PV的解决方法就是通过调整相位使得帧和帧之间的频率值无缝衔接，下面简要介绍时域信号和频率和相位的关系。

![image](https://user-images.githubusercontent.com/88413945/185905668-8cd5e66d-ceef-4ba8-a4ef-74c4668002d4.png)

*图6. 相位修正*

为了理解相位声码器，让我们看看图？所示场景。灰色正弦曲线表示原始音频信号的k次频率Ω。从t1时刻到t2时刻是两帧信号的起始点。两帧之间的时差是 $∆t=H_a/Fs$ ，其中Ha是帧移，Fs是信号采样频率。对于频率为Ω的原始信号来说，从t1到t2点，其相位天然递进了 $Ω∆t$ 个单位，就像绕圆一周是 $2π$ ，2周 $4π$ 等。

$$φ2=φ1+Ω∆t$$

观察图中红色绿色曲线发现由于计算过程产生的误差，上面等式需要修改为

$$φ2=φ1+Ω∆t+φ_Err$$

如图中蓝色椭圆内红色和绿色曲线的瞬时相位差为 $φErr$ 。

我们可以通过1、2两帧的误差计算φErr来预测第0帧的相位，以此类推，可以用第2、3帧的误差来预测第1帧的相位。所以在实验中，我们的计算结果比原始数据少两列。

## PV流程

依据PV核心思想搭建的音频变速器有三大步骤构成：分析、处理、合成

![image](https://user-images.githubusercontent.com/88413945/185905950-8931f5de-16a7-46dd-89ca-46bac1ff310d.png)

*图7. PV流程框图*

- 分析步骤，我们需要将时域信号进行分帧、加窗，分别计算得到频谱矩阵；  
- 处理步骤，根据时域缩放因子对频谱矩阵作精确计算，以确保频率维持不变；  
- 合成步骤，是分析步骤的逆操作，将频谱重叠求和还原为时域信号。  

### 分析

在分析阶段中，我们需要对时域信号进行分帧、加窗、计算频谱

#### 分帧

分帧(frame)的概念和上一次实验中分割信号的目的相同，都是为了获取更好的结果。但和上次实验的区别是，分帧一般涉及到重叠(overlap)。例如，在先前的实验中，100点序列以20为帧长可以分为5段。分帧的重叠指的是如仍以100点序列，20点帧长进行分段，第一段是1-20，第二段则不是21-40，而是5-24或10-29等我们需要定义一个新的变量叫做帧移(hop size)，指的是两帧信号之间的距离。常用帧移的设定在帧长的25%~75%。

![image](https://user-images.githubusercontent.com/88413945/185906176-8378458a-6d8e-4f48-b958-14783cb2092f.png)

*图8. 对信号分帧后对每帧信号作拉伸或压缩处理后再重建*

从图上可以看出，经过分帧后，时域信号从一维向量变为二维矩阵，x(t)的大小是窗长乘以窗数。

#### 加窗

分帧以后，我们还需要对每一帧信号作加窗(window)处理。如图所示左侧一帧信号乘以窗函数得到右侧信号。我们发现原始帧信号的两端被削弱了，这样当我们分析处理的时候，得到的频谱图会更加准确。图中窗函数名为“Hamming Window”，中文为汉明窗，此外，我们还有汉宁窗，布莱克曼窗，三角窗等，都是作加窗处理时可选择的方法。
 
![image](https://user-images.githubusercontent.com/88413945/185906297-98f191d3-d2df-435f-a462-1713afbbc7f4.png)

*图9. 时域信号（左）、汉明窗（中）、加窗后时域信号（右）*

***简单解释***

![image](https://user-images.githubusercontent.com/88413945/185906363-50095098-90ab-49b6-b20d-bfad95aaaa48.png)

*图10. 加窗叠加*

从图中可以看到在一帧中，之前的频率分量叠加为红线，当前频率分量为蓝线，两者的融合由于尾端削弱而更加平滑。为了达到同样的目的，我们在合成阶段对时域信号进行重叠相加时也会用到加窗技术。

#### FFT

在现代数字信号处理中，我们对时域信号的频谱分析都是通过fft计算得到的。fft是dft的快速算法，其本质仍然是对时间信号作频域转换的工具。

$$x[n]=\frac{1}{N} \sum_{k=0}^{N-1} X[k] e^{j 2\pi \frac{k}{N} n}$$

根据前文所述，我们对信号进行分帧和加窗，并对每一帧信号作fft计算后得到下式

$$x[n]=\sum_{k_r]=1}^{I[n]} A[n, k_r] e^{j \phi_a[n,k_r]}, n \ge 0$$

式中，A[m,k]表示第m帧k频率的幅度， $φa[m,k]$ 表示第m帧中k频率的相位，下表a表示分析阶段。假设窗长为N，帧移为Ha，信号x[n]一共被分为numberFrames帧，则 $A[m,k]$ 和 $φa[m,k]$ 都是大小为N*numberFrames的复数矩阵。每一个列向量都代表一帧信号的频谱。

### 处理阶段

在处理阶段，我们主要目的是为了计算变速后的相位谱 $φs[m,k]$ ，下标s表示用于合成信号。

$$y[n]=\sum_{k_r]=1}^{I[n]} A[n, k_r] e^{j \phi_s[n,k_r]}, n \ge 0$$

根据图4，首先依据缩放因子 $α=Rs/Ra$ 建立新的时间序列。在新的时间序列中，需要以抽取或插值方法得到合成阶段的 $φs[m,k]$ 

根据公式，第m+1帧的相位取决于第m帧的相位以及其他信息，有

$$\phi_s[m+1,k]=φ_s[m,k]+Ω∆t+φ_Err^(m:m-1)$$

在计算时需要注意的问题是由于相位在fft计算中是被限定在-π到π的范围内而实际上随着时间的递增相位是在一直增长的。也就是说，第m+1帧的0点瞬时相位和第m帧的0点瞬时相位天然相差了 $2\pi\ast\frac{Ha}{N}$ ，其中Ha是分析阶段帧移，N是一帧信号长度。这一部分需要加入到 $\phi s[m+1,k]$ 中去。

### 合成阶段

合成阶段是分析阶段的逆运算，主要将频谱矩阵作ifft后再加窗再重叠相加得到重建后的时域信号。

## 练习

本次实验分为4个练习，第4个练习文件作为总函数，不需要补充代码，但请详细了解其调用其他函数的流程  
- ex1_analysis 分析阶段函数  
- ex2_process 处理阶段函数  
- ex3_synthesis 合成阶段函数  
- ex4_all	总函数  

本次实验不舍批改程序，如ex4_all运行正常且输出音轨合理则可以通过。


